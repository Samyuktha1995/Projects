# -*- coding: utf-8 -*-
"""Ensemble on CIFAR10

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FHOZOT7QlhtKiB28SuvNN5Gy8L_ud3Zc
"""

from keras.models import Model, Input
from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Average, Dropout
from keras.utils import to_categorical
from keras.losses import categorical_crossentropy
from keras.callbacks import ModelCheckpoint, TensorBoard
from keras.optimizers import Adam
from keras.datasets import cifar10
import numpy as np

(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train = x_train/255
x_test = x_test/255
y_train = to_categorical(y_train, 10)

print("x_train shape: ",format(x_train.shape))
print("y_train shape: ",format(y_train.shape))
print("x_test shape: ",format(x_test.shape))
print("y_test shape: ",format(y_test.shape))

input_shape = x_train[0,:,:,:].shape
model_input = Input(shape=input_shape)

#First CNN - ConvPool cnn

def conv_pool_cnn(model_input):
  x = Conv2D(96, (3,3), activation='relu', padding='same')(model_input)
  x = Conv2D(96, (3,3), activation='relu', padding='same')(x)
  x = Conv2D(96, (3,3), activation='relu', padding='same')(x)
  x = MaxPooling2D(pool_size = (3,3), strides = 2)(x)
  x = Conv2D(192, (3,3), activation='relu', padding='same')(x)
  x = Conv2D(192, (3,3), activation='relu', padding='same')(x)
  x = Conv2D(192, (3,3), activation='relu', padding='same')(x)
  x = MaxPooling2D(pool_size = (3,3), strides = 2)(x)
  x = Conv2D(192, (3,3), activation='relu', padding='same')(x)
  x = Conv2D(192, (1,1), activation='relu')(x)
  x = Conv2D(10, (1,1))(x) # No activation here, since its passing through Global Average Pooling layer
  x = GlobalAveragePooling2D()(x)
  x = Activation(activation='softmax')(x)
  
  model = Model(model_input, x, name='conv_pool_cnn')
  
  return model

#instantiate the model
convPoolCnnModel = conv_pool_cnn(model_input)

def compile_and_train(model, num_epochs):
  model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['acc'])
 # history = model.fit(x=x_train, y=y_train, batch_size=32, epochs=num_epochs, verbose=1, validation_split=0.2)
  
  
  filepath = 'weights'+ model.name + '.{epoch:02d}-{loss:.2f}.hdf5'
  
  checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True, save_best_only=True, mode='auto', period=1)
  
  tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=32)
  
  history = model.fit(x=x_train, y=y_train, batch_size=32, epochs=num_epochs, verbose=1, callbacks=[checkpoint, tensor_board], validation_split=0.2)
   
 
  return history

_ = compile_and_train(convPoolCnnModel, num_epochs=5)

#evaluate the model

def evaluate_error(model):
  pred = model.predict(x_test, batch_size=32)
  pred = np.argmax(pred, axis=1)
  pred = np.expand_dims(pred, axis=1)
  error = np.sum(np.not_equal(pred,y_test))/y_test.shape[0]
  
  return error

evaluate_error(convPoolCnnModel)

#Second Model

def all_cnn(model_input):
  x = Conv2D(96, (3,3), activation='relu', padding='same')(model_input)
  x = Conv2D(96, (3,3), activation='relu', padding='same')(x)
  x = Conv2D(96, (3,3), activation='relu', padding='same', strides=2)(x)
  x = Conv2D(192, (3,3), activation='relu', padding='same')(x)
  x = Conv2D(192, (3,3), activation='relu', padding='same')(x)
  x = Conv2D(192, (3,3), activation='relu', padding='same', strides=2)(x)
  x = Conv2D(192, (3,3), activation='relu', padding='same')(x)
  x = Conv2D(192, (1,1), activation='relu')(x)
  x = Conv2D(10, (1,1))(x) # No activation here, since its passing through Global Average Pooling layer
  x = GlobalAveragePooling2D()(x)
  x = Activation(activation='softmax')(x)
  
  model = Model(model_input, x, name='all_cnn')
  
  return model

allCnnModel = all_cnn(model_input)
_ = compile_and_train(allCnnModel, num_epochs=5)

evaluate_error(allCnnModel)

#3rd model Network-in-Network model 

def nin_cnn(model_input):
  
  #mlp conv block1
  x = Conv2D(32, (5,5), activation='relu', padding='valid')(model_input)
  x = Conv2D(32, (1,1), activation='relu')(x)
  x = Conv2D(32, (1,1), activation='relu')(x)
  x = MaxPooling2D((2,2))(x)
  x = Dropout(0.5)(x)
  
  #mlp conv block2
  x = Conv2D(64, (3,3), activation='relu', padding='valid')(x)
  x = Conv2D(64, (1,1), activation='relu')(x)
  x = Conv2D(64, (1,1), activation='relu')(x)
  x = MaxPooling2D((2,2))(x)
  x = Dropout(0.5)(x)
  
  #mlp conv block3
  x = Conv2D(128, (3,3), activation='relu', padding='valid')(x)
  x = Conv2D(32, (1,1), activation='relu')(x)
  x = Conv2D(10, (1,1))(x)
  
  x = GlobalAveragePooling2D()(x)
  x = Activation(activation='softmax')(x)
  
  model = Model(model_input, x, name='nin_model')
  
  return model

ninModel = nin_cnn(model_input)
_ = compile_and_train(ninModel, num_epochs=5)

evaluate_error(ninModel)

conv_pool_cnn_model = conv_pool_cnn(model_input)
all_cnn_model = all_cnn(model_input)
nin_cnn_model = nin_cnn(model_input)

conv_pool_cnn_model.load_weights('weights/conv_pool_cnn.29-0.10.hdf5')
all_cnn_model.load_weights('weights/all_cnn.30-0.08.hdf5')
nin_cnn_model.load_weights('weights/nin_cnn.30-0.93.hdf5')

models = [conv_pool_cnn_model, all_cnn_model, nin_cnn_model]